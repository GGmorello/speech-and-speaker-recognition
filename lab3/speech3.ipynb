{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "mypCdovxedLZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from lab3_tools import *\n",
        "from lab3_proto import *\n",
        "from lab2_tools import *\n",
        "from lab2_proto import *\n",
        "from lab1_proto import *\n",
        "from lab1_tools import *\n",
        "import torch\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzd0FhmkdNuP",
        "outputId": "37671432-2c73-4fd2-c594-88b93b3b27d7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['ah_0',\n",
              " 'ah_1',\n",
              " 'ah_2',\n",
              " 'ao_0',\n",
              " 'ao_1',\n",
              " 'ao_2',\n",
              " 'ay_0',\n",
              " 'ay_1',\n",
              " 'ay_2',\n",
              " 'eh_0',\n",
              " 'eh_1',\n",
              " 'eh_2',\n",
              " 'ey_0',\n",
              " 'ey_1',\n",
              " 'ey_2',\n",
              " 'f_0',\n",
              " 'f_1',\n",
              " 'f_2',\n",
              " 'ih_0',\n",
              " 'ih_1',\n",
              " 'ih_2',\n",
              " 'iy_0',\n",
              " 'iy_1',\n",
              " 'iy_2',\n",
              " 'k_0',\n",
              " 'k_1',\n",
              " 'k_2',\n",
              " 'n_0',\n",
              " 'n_1',\n",
              " 'n_2',\n",
              " 'ow_0',\n",
              " 'ow_1',\n",
              " 'ow_2',\n",
              " 'r_0',\n",
              " 'r_1',\n",
              " 'r_2',\n",
              " 's_0',\n",
              " 's_1',\n",
              " 's_2',\n",
              " 'sil_0',\n",
              " 'sil_1',\n",
              " 'sil_2',\n",
              " 'sp_0',\n",
              " 't_0',\n",
              " 't_1',\n",
              " 't_2',\n",
              " 'th_0',\n",
              " 'th_1',\n",
              " 'th_2',\n",
              " 'uw_0',\n",
              " 'uw_1',\n",
              " 'uw_2',\n",
              " 'v_0',\n",
              " 'v_1',\n",
              " 'v_2',\n",
              " 'w_0',\n",
              " 'w_1',\n",
              " 'w_2',\n",
              " 'z_0',\n",
              " 'z_1',\n",
              " 'z_2']"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "phoneHMMs = np.load('lab2_models_all.npz', allow_pickle=True)['phoneHMMs'].item()\n",
        "phones = sorted(phoneHMMs.keys())\n",
        "nstates = {phone: phoneHMMs[phone]['means'].shape[0] for phone in phones}\n",
        "stateList = [ph + '_' + str(id) for ph in phones for id in range(nstates[ph])]\n",
        "stateList"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "mYZRfyrk7No0"
      },
      "outputs": [],
      "source": [
        "np.savez(\"./statelist.npz\",stateList)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "GyReqLXS7XaU"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('man', 'ae', 'z9z6531', 'a')"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_example, _= loadAudio('tidigits/disc_4.1.1/tidigits/train/man/ae/z9z6531a.wav')\n",
        "path2info('tidigits/disc_4.1.1/tidigits/train/man/ae/z9z6531a.wav')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "px3Px2ptf4jr",
        "outputId": "4530db17-13a9-45e1-9646-34c6bb0bfd35"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['z', '4', '3']"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "filename = 'tidigits/disc_4.1.1/tidigits/train/man/nw/z43a.wav'\n",
        "samples, samplingrate = loadAudio(filename)\n",
        "lmfcc = mfcc(samples)\n",
        "wordTrans = list(path2info(filename)[2])\n",
        "wordTrans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Ou5sRS0jhOru"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['sil',\n",
              " 'z',\n",
              " 'iy',\n",
              " 'r',\n",
              " 'ow',\n",
              " 'sp',\n",
              " 'f',\n",
              " 'ao',\n",
              " 'r',\n",
              " 'sp',\n",
              " 'th',\n",
              " 'r',\n",
              " 'iy',\n",
              " 'sil']"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from prondict import prondict\n",
        "phoneTrans = words2phones(wordTrans, prondict)\n",
        "phoneTrans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "WriefTUuhVpg"
      },
      "outputs": [],
      "source": [
        "utteranceHMM = concatHMMs(phoneHMMs, phoneTrans)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "QIzhnQONhebR"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'r_1'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stateTrans = [phone + '_' + str(stateid) for phone in phoneTrans\n",
        "                  for stateid in range(nstates[phone])]\n",
        "stateTrans[10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "htp8Z6N2AyYS"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/cubeddu_laflame/Desktop/speech-and-speaker-recognition-2/lab3/lab3_proto.py:66: RuntimeWarning: divide by zero encountered in log\n",
            "  _, viterbi_path = viterbi(observation_log_likelihood, np.log(utterance_HMM['startprob']), np.log(utterance_HMM['transmat']), forceFinalState=True)\n"
          ]
        }
      ],
      "source": [
        "viterbiStateTrans = forcedAlignment(lmfcc, phoneHMMs, phoneTrans)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "qm3LtwHshlx3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'0 0.01 sil_0\\n0.01 0.19000000000000003 sil_1\\n0.19000000000000003 0.20000000000000004 sil_2\\n0.20000000000000004 0.24000000000000007 z_0\\n0.24000000000000007 0.25000000000000006 z_1\\n0.25000000000000006 0.36000000000000015 z_2\\n0.36000000000000015 0.4400000000000002 iy_0\\n0.4400000000000002 0.45000000000000023 iy_1\\n0.45000000000000023 0.46000000000000024 iy_2\\n0.46000000000000024 0.5600000000000003 r_0\\n0.5600000000000003 0.5700000000000003 r_1\\n0.5700000000000003 0.5800000000000003 r_2\\n0.5800000000000003 0.5900000000000003 ow_0\\n0.5900000000000003 0.6000000000000003 ow_1\\n0.6000000000000003 0.6900000000000004 ow_2\\n0.6900000000000004 0.7000000000000004 sp_0\\n0.7000000000000004 0.7100000000000004 f_0\\n0.7100000000000004 0.8100000000000005 f_1\\n0.8100000000000005 0.8200000000000005 f_2\\n0.8200000000000005 0.8300000000000005 ao_0\\n0.8300000000000005 0.9700000000000006 ao_1\\n0.9700000000000006 1.0800000000000007 ao_2\\n1.0800000000000007 1.1100000000000008 r_0\\n1.1100000000000008 1.1200000000000008 r_1\\n1.1200000000000008 1.1300000000000008 r_2\\n1.1300000000000008 1.1400000000000008 sp_0\\n1.1400000000000008 1.2300000000000009 th_0\\n1.2300000000000009 1.260000000000001 th_1\\n1.260000000000001 1.270000000000001 th_2\\n1.270000000000001 1.360000000000001 r_0\\n1.360000000000001 1.370000000000001 r_1\\n1.370000000000001 1.380000000000001 r_2\\n1.380000000000001 1.480000000000001 iy_0\\n1.480000000000001 1.500000000000001 iy_1\\n1.500000000000001 1.5800000000000012 iy_2\\n1.5800000000000012 1.7800000000000014 sil_0\\n'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "frames2trans(viterbiStateTrans, outfilename='z43a.lab')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "WzwTi83ohvwf"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[11], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m wordTrans \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(path2info(filename)[\u001b[39m2\u001b[39m])\n\u001b[1;32m     11\u001b[0m phoneTrans \u001b[39m=\u001b[39m words2phones(wordTrans, prondict)\n\u001b[0;32m---> 12\u001b[0m targets \u001b[39m=\u001b[39m forcedAlignment(lmfcc, phoneHMMs, phoneTrans)\n\u001b[1;32m     13\u001b[0m traindata\u001b[39m.\u001b[39mappend({\u001b[39m'\u001b[39m\u001b[39mfilename\u001b[39m\u001b[39m'\u001b[39m: filename, \u001b[39m'\u001b[39m\u001b[39mlmfcc\u001b[39m\u001b[39m'\u001b[39m: lmfcc, \u001b[39m'\u001b[39m\u001b[39mmspec\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mmspec\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtargets\u001b[39m\u001b[39m'\u001b[39m: targets})\n",
            "File \u001b[0;32m~/Desktop/speech-and-speaker-recognition-2/lab3/lab3_proto.py:66\u001b[0m, in \u001b[0;36mforcedAlignment\u001b[0;34m(lmfcc, phoneHMMs, phoneTrans)\u001b[0m\n\u001b[1;32m     63\u001b[0m observation_log_likelihood \u001b[39m=\u001b[39m log_multivariate_normal_density_diag(lmfcc, utterance_HMM[\u001b[39m'\u001b[39m\u001b[39mmeans\u001b[39m\u001b[39m'\u001b[39m], utterance_HMM[\u001b[39m'\u001b[39m\u001b[39mcovars\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     65\u001b[0m \u001b[39m# Apply Viterbi algorithm\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m _, viterbi_path \u001b[39m=\u001b[39m viterbi(observation_log_likelihood, np\u001b[39m.\u001b[39;49mlog(utterance_HMM[\u001b[39m'\u001b[39;49m\u001b[39mstartprob\u001b[39;49m\u001b[39m'\u001b[39;49m]), np\u001b[39m.\u001b[39;49mlog(utterance_HMM[\u001b[39m'\u001b[39;49m\u001b[39mtransmat\u001b[39;49m\u001b[39m'\u001b[39;49m]), forceFinalState\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     68\u001b[0m \u001b[39m# Convert state path to phoneme_index format\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[39mfor\u001b[39;00m index \u001b[39min\u001b[39;00m viterbi_path:\n",
            "File \u001b[0;32m~/Desktop/speech-and-speaker-recognition-2/lab3/lab2_proto.py:151\u001b[0m, in \u001b[0;36mviterbi\u001b[0;34m(log_emlik, log_startprob, log_transmat, forceFinalState)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(log_emlik\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]):\n\u001b[1;32m    150\u001b[0m         delta[i,j]\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mmax(delta[i\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m+\u001b[39mlog_transmat[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,j])\u001b[39m+\u001b[39mlog_emlik[i,j]\n\u001b[0;32m--> 151\u001b[0m         psi[i,j]\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39;49margmax(delta[i\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]\u001b[39m+\u001b[39;49mlog_transmat[:\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m,j])\n\u001b[1;32m    152\u001b[0m \u001b[39mif\u001b[39;00m forceFinalState:\n\u001b[1;32m    153\u001b[0m     viterbi_path \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(log_emlik\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], dtype\u001b[39m=\u001b[39m\u001b[39mint\u001b[39m)\n",
            "File \u001b[0;32m<__array_function__ internals>:177\u001b[0m, in \u001b[0;36margmax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import os\n",
        "traindata = []\n",
        "for root, dirs, files in os.walk('tidigits/disc_4.1.1/tidigits/train'):\n",
        "    for file in files:\n",
        "      if file.endswith('.wav'):\n",
        "          filename = os.path.join(root, file)\n",
        "          samples, samplingrate = loadAudio(filename)\n",
        "          lmfcc = mfcc(samples)\n",
        "          spec = mspec(samples)\n",
        "          wordTrans = list(path2info(filename)[2])\n",
        "          phoneTrans = words2phones(wordTrans, prondict)\n",
        "          targets = forcedAlignment(lmfcc, phoneHMMs, phoneTrans)\n",
        "          traindata.append({'filename': filename, 'lmfcc': lmfcc, 'mspec': 'mspec', 'targets': targets})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_viMqjeC2YL"
      },
      "outputs": [],
      "source": [
        "def loaddata():\n",
        "    traindata = []\n",
        "    for root, dirs, files in os.walk():\n",
        "        for file in files:\n",
        "          if file.endswith('.wav'):\n",
        "              filename = os.path.join(root, file)\n",
        "              samples, samplingrate = loadAudio(filename)\n",
        "              lmfcc = mfcc(samples)\n",
        "              spec = mspec(samples)\n",
        "              wordTrans = list(path2info(filename)[2])\n",
        "              phoneTrans = words2phones(wordTrans, prondict)\n",
        "              targets = forcedAlignment(lmfcc, phoneHMMs, phoneTrans)\n",
        "              traindata.append({'filename': filename, 'lmfcc': lmfcc, 'mspec': 'mspec', 'targets': targets})\n",
        "    return traindata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4uSLZhA1hvyL"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "loaddata() takes 0 positional arguments but 1 was given",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[69], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m traindata \u001b[39m=\u001b[39m loaddata(\u001b[39m'\u001b[39;49m\u001b[39mtidigits/disc_4.1.1/tidigits/train\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      2\u001b[0m np\u001b[39m.\u001b[39msavez(\u001b[39m'\u001b[39m\u001b[39mtraindata.npz\u001b[39m\u001b[39m'\u001b[39m, traindata\u001b[39m=\u001b[39mtraindata)\n",
            "\u001b[0;31mTypeError\u001b[0m: loaddata() takes 0 positional arguments but 1 was given"
          ]
        }
      ],
      "source": [
        "traindata = loaddata('tidigits/disc_4.1.1/tidigits/train')\n",
        "np.savez('traindata.npz', traindata=traindata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "79QdajdeCyhT"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "loaddata() takes 0 positional arguments but 1 was given",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[72], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m testdata \u001b[39m=\u001b[39m loaddata(\u001b[39m'\u001b[39;49m\u001b[39mtidigits/disc_4.1.1/tidigits/test\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      2\u001b[0m np\u001b[39m.\u001b[39msavez(\u001b[39m'\u001b[39m\u001b[39mtestdata.npz\u001b[39m\u001b[39m'\u001b[39m, testdata\u001b[39m=\u001b[39mtestdata)\n",
            "\u001b[0;31mTypeError\u001b[0m: loaddata() takes 0 positional arguments but 1 was given"
          ]
        }
      ],
      "source": [
        "testdata = loaddata('tidigits/disc_4.1.1/tidigits/test')\n",
        "np.savez('testdata.npz', testdata=testdata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "VLuQNlSOCyn0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1507392\n"
          ]
        }
      ],
      "source": [
        "train_data = np.load('traindata.npz', allow_pickle=True)['traindata']\n",
        "n_val = round(len(train_data)//10)\n",
        "testdata=np.load('testdata.npz', allow_pickle=True)['testdata']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "iKtvA0aiDwkV"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'data' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[31], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m np\u001b[39m.\u001b[39msavez(\u001b[39m'\u001b[39m\u001b[39mtrain.npz\u001b[39m\u001b[39m'\u001b[39m, train\u001b[39m=\u001b[39mtrain)\n\u001b[1;32m      6\u001b[0m np\u001b[39m.\u001b[39msavez(\u001b[39m'\u001b[39m\u001b[39mval.npz\u001b[39m\u001b[39m'\u001b[39m, val\u001b[39m=\u001b[39mval)\n\u001b[0;32m----> 7\u001b[0m data\u001b[39m.\u001b[39mkeys()\n",
            "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
          ]
        }
      ],
      "source": [
        "indexes = np.random.permutation(len(train_data))\n",
        "train = np.take(train_data,indexes)\n",
        "val = train[:n_val]\n",
        "train = train[n_val:]\n",
        "np.savez('train.npz', train=train)\n",
        "np.savez('val.npz', val=val)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "brXJT_6WKllf"
      },
      "source": [
        "## Acoustic Context (Dynamic Features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "gf1X0yAYJc77"
      },
      "outputs": [],
      "source": [
        "def get_features(data, dynamic=True):\n",
        "    lmfcc_dim = data[0]['lmfcc'].shape[1]\n",
        "    mspec_dim = data[0]['mspec'].shape[1]\n",
        "    total_frames = sum([len(x['targets']) for x in data])\n",
        "    print(total_frames)\n",
        "    pad_size = 3\n",
        "    if dynamic:\n",
        "        num_features = 7\n",
        "    else:\n",
        "        num_features = 1\n",
        "    dynamic2 = dynamic\n",
        "    dynamic = False\n",
        "    mfcc_features = np.zeros((total_frames, lmfcc_dim * num_features))\n",
        "    mspec_features = np.zeros((total_frames, mspec_dim * num_features))\n",
        "    targets = []\n",
        "    current_frame_idx = 0 \n",
        "    for i, utterance in enumerate(data):\n",
        "        lmfcc_padded = np.pad(utterance['lmfcc'], pad_width=((pad_size, pad_size), (0, 0)), mode='reflect')\n",
        "        mspec_padded = np.pad(utterance['mspec'], pad_width=((pad_size, pad_size), (0, 0)), mode='reflect')\n",
        "        num_frames = len(utterance['targets'])\n",
        "        for frame_idx in range(num_frames):\n",
        "            if dynamic2:\n",
        "                start = frame_idx\n",
        "                end = frame_idx + num_features\n",
        "                if start < pad_size:\n",
        "                    start = pad_size\n",
        "                    end = pad_size + num_features\n",
        "                elif end > num_frames - pad_size:\n",
        "                    start = num_frames - pad_size - num_features\n",
        "                    end = num_frames - pad_size\n",
        "                mfcc_features[current_frame_idx] = np.hstack(lmfcc_padded[start:end])\n",
        "                mspec_features[current_frame_idx] = np.hstack(mspec_padded[start:end])\n",
        "            else:\n",
        "                mfcc_features[current_frame_idx] = utterance['lmfcc'][frame_idx]\n",
        "                mspec_features[current_frame_idx] = utterance['mspec'][frame_idx]\n",
        "\n",
        "            if frame_idx < len(utterance['targets']):\n",
        "                targets.append(utterance['targets'][frame_idx])\n",
        "            else:\n",
        "                # Handle case when 'targets' list is shorter than expected\n",
        "                targets.append(None)   \n",
        "            current_frame_idx += 1\n",
        "    \n",
        "    return mfcc_features, mspec_features, targets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "lH2eD2YqEvtP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1354824\n",
            "152568\n",
            "1527014\n"
          ]
        }
      ],
      "source": [
        "d_lmfcc_train, d_mspec_train, train_y = get_features(train,dynamic=True)\n",
        "d_lmfcc_val, d_mspec_val, val_y = get_features(val,dynamic=True)\n",
        "d_lmfcc_test, d_mspec_test, test_y = get_features(testdata,dynamic=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "LuLoFidZImcK"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1354824\n",
            "152568\n",
            "1527014\n"
          ]
        }
      ],
      "source": [
        "lmfcc_train_x, mspec_train_x, _ = get_features(train,dynamic=False)\n",
        "lmfcc_val_x, mspec_val_x, _ = get_features(val,dynamic=False)\n",
        "lmfcc_test_x, mspec_test_x, _ = get_features(testdata,dynamic=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "HIU3W32qH1rU"
      },
      "outputs": [],
      "source": [
        "np.savez('d_lmfcc_train.npz', d_lmfcc_train=d_lmfcc_train)\n",
        "np.savez('d_lmfcc_val.npz', d_lmfcc_val=d_lmfcc_val)\n",
        "np.savez('d_lmfcc_test.npz', d_lmfcc_test=d_lmfcc_test)\n",
        "\n",
        "np.savez('d_mspec_train.npz', d_mspec_train=d_mspec_train)\n",
        "np.savez('d_mspec_val.npz', d_mspec_val=d_mspec_val)\n",
        "np.savez('d_mspec_test.npz', d_mspec_test=d_mspec_test)\n",
        "\n",
        "np.savez('train_y',train_y=train_y)\n",
        "np.savez('val_y',val_y=val_y)\n",
        "np.savez('test_y',test_y=test_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "t3o1RJqyIllu"
      },
      "outputs": [],
      "source": [
        "np.savez('lmfcc_train_x.npz', lmfcc_train_x=lmfcc_train_x)\n",
        "np.savez('lmfcc_val_x.npz', lmfcc_val_x=lmfcc_val_x)\n",
        "np.savez('lmfcc_test_x.npz', lmfcc_test_x=lmfcc_test_x)\n",
        "np.savez('mspec_train_x.npz', mspec_train_x=mspec_train_x)\n",
        "np.savez('mspec_val_x.npz', mspec_val_x=mspec_val_x)\n",
        "np.savez('mspec_test_x.npz', mspec_test_x=mspec_test_x)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "eYocnuqiKd8m"
      },
      "source": [
        "## Feature Standardisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "KdFf58YyLiuu"
      },
      "outputs": [],
      "source": [
        "stateList = np.load('statelist.npz',allow_pickle=True)['arr_0']\n",
        "output_dim = len(stateList)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "quPL2ihwKdo3"
      },
      "outputs": [],
      "source": [
        "#You can use the StandardScaler from sklearn.preprocessing in order to achieve this. In case you normalise over the whole training set, save the normalisation coefficients and reuse them to normalise the validation and test set. In this case, it is also easier to perform the following step before standardisation\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(d_lmfcc_train)\n",
        "d_lmfcc_train = scaler.transform(d_lmfcc_train)\n",
        "d_lmfcc_val = scaler.transform(d_lmfcc_val)\n",
        "d_lmfcc_test = scaler.transform(d_lmfcc_test)\n",
        "scaler2=StandardScaler()\n",
        "scaler2.fit(d_mspec_train)\n",
        "d_mspec_train = scaler2.transform(d_mspec_train)\n",
        "d_mspec_val = scaler2.transform(d_mspec_val)\n",
        "d_mspec_test = scaler2.transform(d_mspec_test)\n",
        "scaler3=StandardScaler()\n",
        "scaler3.fit(lmfcc_train_x)\n",
        "lmfcc_train_x = scaler3.transform(lmfcc_train_x)\n",
        "lmfcc_val_x = scaler3.transform(lmfcc_val_x)\n",
        "lmfcc_test_x = scaler3.transform(lmfcc_test_x)\n",
        "scaler4=StandardScaler()\n",
        "scaler4.fit(mspec_train_x)\n",
        "mspec_train_x = scaler4.transform(mspec_train_x)\n",
        "mspec_val_x = scaler4.transform(mspec_val_x)\n",
        "mspec_test_x = scaler4.transform(mspec_test_x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "J_ZIWhwbJXLg"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "import torch.nn.functional as F\n",
        "lmfcc_train_x = lmfcc_train_x.astype('float32')\n",
        "lmfcc_val_x = lmfcc_val_x.astype('float32')\n",
        "lmfcc_test_x = lmfcc_test_x.astype('float32')\n",
        "output_dim = len(stateList)\n",
        "\n",
        "# Convert string labels to numerical format\n",
        "label_encoder = LabelEncoder()\n",
        "train_y_encoded = label_encoder.fit_transform(train_y)\n",
        "val_y_encoded = label_encoder.fit_transform(val_y)\n",
        "test_y_encoded = label_encoder.fit_transform(test_y)\n",
        "# Apply one-hot encoding to the numerical labels\n",
        "one_hot_train_y = F.one_hot(torch.tensor(train_y_encoded), num_classes=output_dim)\n",
        "one_hot_val_y = F.one_hot(torch.tensor(val_y_encoded), num_classes=output_dim)\n",
        "one_hot_test_y = F.one_hot(torch.tensor(test_y_encoded), num_classes=output_dim)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "lmfcc_train_x shape:  (1354824, 13)\n",
            "lmfcc_val_x shape:  (152568, 13)\n",
            "lmfcc_test_x shape:  (1527014, 13)\n",
            "mspec_train_x shape:  (1354824, 40)\n",
            "mspec_val_x shape:  (152568, 40)\n",
            "mspec_test_x shape:  (1527014, 40)\n",
            "d_lmfcc_train shape:  (1354824, 91)\n",
            "d_lmfcc_val shape:  (152568, 91)\n",
            "d_lmfcc_test shape:  (1527014, 91)\n",
            "d_mspec_train shape:  (1354824, 280)\n",
            "d_mspec_val shape:  (152568, 280)\n",
            "d_mspec_test shape:  (1527014, 280)\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'list' object has no attribute 'shape'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[89], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39md_mspec_val shape: \u001b[39m\u001b[39m\"\u001b[39m,d_mspec_val\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     15\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39md_mspec_test shape: \u001b[39m\u001b[39m\"\u001b[39m,d_mspec_test\u001b[39m.\u001b[39mshape)\n\u001b[0;32m---> 16\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mtrain_y shape: \u001b[39m\u001b[39m\"\u001b[39m,train_y\u001b[39m.\u001b[39;49mshape)\n\u001b[1;32m     17\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mval_y shape: \u001b[39m\u001b[39m\"\u001b[39m,val_y\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     18\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mtest_y shape: \u001b[39m\u001b[39m\"\u001b[39m,test_y\u001b[39m.\u001b[39mshape)\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
          ]
        }
      ],
      "source": [
        "#reshape lmfcc_train_x removing the last dimension\n",
        "lmfcc_train_x = lmfcc_train_x.reshape(lmfcc_train_x.shape[0],lmfcc_train_x.shape[1])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1354824, 91)\n"
          ]
        }
      ],
      "source": [
        "#save data\n",
        "print(d_lmfcc_train.shape)\n",
        "np.savez('d_lmfcc_train.npz', d_lmfcc_train=d_lmfcc_train)\n",
        "np.savez('d_lmfcc_val.npz', d_lmfcc_val=d_lmfcc_val)\n",
        "np.savez('d_lmfcc_test.npz', d_lmfcc_test=d_lmfcc_test)\n",
        "np.savez('d_mspec_train.npz', d_mspec_train=d_mspec_train)\n",
        "np.savez('d_mspec_val.npz', d_mspec_val=d_mspec_val)\n",
        "np.savez('d_mspec_test.npz', d_mspec_test=d_mspec_test)\n",
        "np.savez('one_hot_train_y.npz', one_hot_train_y=one_hot_train_y)\n",
        "np.savez('one_hot_val_y.npz', one_hot_val_y=one_hot_val_y)\n",
        "np.savez('one_hot_test_y.npz', one_hot_test_y=one_hot_test_y)\n",
        "np.savez('lmfcc_train_x.npz', lmfcc_train_x=lmfcc_train_x)\n",
        "np.savez('lmfcc_val_x.npz', lmfcc_val_x=lmfcc_val_x)\n",
        "np.savez('lmfcc_test_x.npz', lmfcc_test_x=lmfcc_test_x)\n",
        "np.savez('mspec_train_x.npz', mspec_train_x=mspec_train_x)\n",
        "np.savez('mspec_val_x.npz', mspec_val_x=mspec_val_x)\n",
        "np.savez('mspec_test_x.npz', mspec_test_x=mspec_test_x)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
